{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f5bad3d-ca6c-4e72-aac7-e43240eeb3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import ast\n",
    "\n",
    "# Import library with current code functions\n",
    "sys.path.append(os.path.join(\"..\", \"lib\"))\n",
    "import general_functions as gf, files_paths as fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc018577-0cc2-4285-8dcc-297cc4f41946",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAIN_LIST_LABELER = gf.find_files_in_all_subdirectories([fp.DATASET_LOCAL, fp.DATASET_YT], fp.VD_LABELED_L0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "180a1aca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.\\\\result_sequences\\\\DATASET_SEQUENCES_1.CSV',\n",
       " '.\\\\result_sequences\\\\DATASET_SEQUENCES_2.CSV',\n",
       " '.\\\\result_sequences\\\\DATASET_SEQUENCES_3.CSV',\n",
       " '.\\\\result_sequences\\\\DATASET_SEQUENCES_4.CSV',\n",
       " '.\\\\result_sequences\\\\DATASET_SEQUENCES_5.CSV',\n",
       " '.\\\\result_sequences\\\\DATASET_SEQUENCES_6.CSV',\n",
       " '.\\\\result_sequences\\\\DATASET_SEQUENCES_7.CSV']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gf.find_files_in_all_subdirectories([os.path.join('.', 'result_sequences')], '*.CSV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df730c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_string_to_object(label_measure_string):\n",
    "    parsed_object = ast.literal_eval(label_measure_string) \n",
    "    return parsed_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef400c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_emotion_with_min_value(parsed_object):\n",
    "    emotion_with_min_value = min(parsed_object.items(), key=lambda x: x[1][1])\n",
    "    emotion_name, emotion_data = emotion_with_min_value\n",
    "    return emotion_name, emotion_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2b61671-f2b5-4852-aab5-172f6a5f4125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current video (1 of 70): ..\\Dataset\\DD-Local\\VD_D_0000000043\\VD_LABELED_L0.CSV\n",
      "Current video (2 of 70): ..\\Dataset\\DD-Local\\VD_D_0000000044\\VD_LABELED_L0.CSV\n",
      "Current video (3 of 70): ..\\Dataset\\DD-Local\\VD_D_0000000045\\VD_LABELED_L0.CSV\n",
      "Current video (4 of 70): ..\\Dataset\\DD-Local\\VD_D_0000000046\\VD_LABELED_L0.CSV\n",
      "Current video (5 of 70): ..\\Dataset\\DD-Local\\VD_D_0000000047\\VD_LABELED_L0.CSV\n",
      "Current video (6 of 70): ..\\Dataset\\DD-Local\\VD_D_0000000048\\VD_LABELED_L0.CSV\n",
      "Current video (7 of 70): ..\\Dataset\\DD-Local\\VD_D_0000000049\\VD_LABELED_L0.CSV\n",
      "Current video (8 of 70): ..\\Dataset\\DD-Local\\VD_D_0000000050\\VD_LABELED_L0.CSV\n",
      "Current video (9 of 70): ..\\Dataset\\DD-Local\\VD_D_0000000051\\VD_LABELED_L0.CSV\n",
      "Current video (10 of 70): ..\\Dataset\\DD-Local\\VD_D_0000000052\\VD_LABELED_L0.CSV\n",
      "Current video (11 of 70): ..\\Dataset\\DD-Local\\VD_D_0000000053\\VD_LABELED_L0.CSV\n",
      "Current video (12 of 70): ..\\Dataset\\DD-Local\\VD_D_0000000054\\VD_LABELED_L0.CSV\n",
      "Current video (13 of 70): ..\\Dataset\\DD-Local\\VD_D_0000000055\\VD_LABELED_L0.CSV\n",
      "Current video (14 of 70): ..\\Dataset\\DD-Local\\VD_D_0000000056\\VD_LABELED_L0.CSV\n",
      "Current video (15 of 70): ..\\Dataset\\DD-Local\\VD_D_0000000057\\VD_LABELED_L0.CSV\n",
      "Current video (16 of 70): ..\\Dataset\\DD-Local\\VD_D_0000000058\\VD_LABELED_L0.CSV\n",
      "Current video (17 of 70): ..\\Dataset\\DD-Local\\VD_D_0000000059\\VD_LABELED_L0.CSV\n",
      "Current video (18 of 70): ..\\Dataset\\DD-Local\\VD_D_0000000060\\VD_LABELED_L0.CSV\n",
      "Current video (19 of 70): ..\\Dataset\\DD-Local\\VD_D_0000000061\\VD_LABELED_L0.CSV\n",
      "Current video (20 of 70): ..\\Dataset\\DD-Local\\VD_D_0000000062\\VD_LABELED_L0.CSV\n",
      "Current video (21 of 70): ..\\Dataset\\DD-Local\\VD_D_0000000063\\VD_LABELED_L0.CSV\n",
      "Current video (22 of 70): ..\\Dataset\\DD-Local\\VD_D_0000000064\\VD_LABELED_L0.CSV\n",
      "Current video (23 of 70): ..\\Dataset\\DD-Local\\VD_D_0000000065\\VD_LABELED_L0.CSV\n",
      "Current video (24 of 70): ..\\Dataset\\DD-Local\\VD_D_0000000066\\VD_LABELED_L0.CSV\n",
      "Current video (25 of 70): ..\\Dataset\\DD-Local\\VD_D_0000000067\\VD_LABELED_L0.CSV\n",
      "Current video (26 of 70): ..\\Dataset\\DD-Local\\VD_D_0000000068\\VD_LABELED_L0.CSV\n",
      "Current video (27 of 70): ..\\Dataset\\DD-Local\\VD_D_0000000069\\VD_LABELED_L0.CSV\n",
      "Current video (28 of 70): ..\\Dataset\\DD-Local\\VD_D_0000000070\\VD_LABELED_L0.CSV\n",
      "Current video (29 of 70): ..\\Dataset\\YT-Online\\VD_Y_0000000001\\VD_LABELED_L0.CSV\n",
      "Current video (30 of 70): ..\\Dataset\\YT-Online\\VD_Y_0000000002\\VD_LABELED_L0.CSV\n",
      "Current video (31 of 70): ..\\Dataset\\YT-Online\\VD_Y_0000000003\\VD_LABELED_L0.CSV\n",
      "Current video (32 of 70): ..\\Dataset\\YT-Online\\VD_Y_0000000004\\VD_LABELED_L0.CSV\n",
      "Current video (33 of 70): ..\\Dataset\\YT-Online\\VD_Y_0000000005\\VD_LABELED_L0.CSV\n",
      "Current video (34 of 70): ..\\Dataset\\YT-Online\\VD_Y_0000000006\\VD_LABELED_L0.CSV\n",
      "Current video (35 of 70): ..\\Dataset\\YT-Online\\VD_Y_0000000007\\VD_LABELED_L0.CSV\n",
      "Current video (36 of 70): ..\\Dataset\\YT-Online\\VD_Y_0000000008\\VD_LABELED_L0.CSV\n",
      "Current video (37 of 70): ..\\Dataset\\YT-Online\\VD_Y_0000000009\\VD_LABELED_L0.CSV\n",
      "Current video (38 of 70): ..\\Dataset\\YT-Online\\VD_Y_0000000010\\VD_LABELED_L0.CSV\n",
      "Current video (39 of 70): ..\\Dataset\\YT-Online\\VD_Y_0000000011\\VD_LABELED_L0.CSV\n",
      "Current video (40 of 70): ..\\Dataset\\YT-Online\\VD_Y_0000000012\\VD_LABELED_L0.CSV\n",
      "Current video (41 of 70): ..\\Dataset\\YT-Online\\VD_Y_0000000013\\VD_LABELED_L0.CSV\n",
      "Current video (42 of 70): ..\\Dataset\\YT-Online\\VD_Y_0000000014\\VD_LABELED_L0.CSV\n",
      "Current video (43 of 70): ..\\Dataset\\YT-Online\\VD_Y_0000000015\\VD_LABELED_L0.CSV\n",
      "Current video (44 of 70): ..\\Dataset\\YT-Online\\VD_Y_0000000016\\VD_LABELED_L0.CSV\n",
      "Current video (45 of 70): ..\\Dataset\\YT-Online\\VD_Y_0000000017\\VD_LABELED_L0.CSV\n",
      "Current video (46 of 70): ..\\Dataset\\YT-Online\\VD_Y_0000000018\\VD_LABELED_L0.CSV\n",
      "Current video (47 of 70): ..\\Dataset\\YT-Online\\VD_Y_0000000019\\VD_LABELED_L0.CSV\n",
      "Current video (48 of 70): ..\\Dataset\\YT-Online\\VD_Y_0000000020\\VD_LABELED_L0.CSV\n",
      "Current video (49 of 70): ..\\Dataset\\YT-Online\\VD_Y_0000000021\\VD_LABELED_L0.CSV\n",
      "Current video (50 of 70): ..\\Dataset\\YT-Online\\VD_Y_0000000022\\VD_LABELED_L0.CSV\n",
      "Current video (51 of 70): ..\\Dataset\\YT-Online\\VD_Y_0000000023\\VD_LABELED_L0.CSV\n",
      "Current video (52 of 70): ..\\Dataset\\YT-Online\\VD_Y_0000000024\\VD_LABELED_L0.CSV\n",
      "Current video (53 of 70): ..\\Dataset\\YT-Online\\VD_Y_0000000025\\VD_LABELED_L0.CSV\n",
      "Current video (54 of 70): ..\\Dataset\\YT-Online\\VD_Y_0000000026\\VD_LABELED_L0.CSV\n",
      "Current video (55 of 70): ..\\Dataset\\YT-Online\\VD_Y_0000000027\\VD_LABELED_L0.CSV\n",
      "Current video (56 of 70): ..\\Dataset\\YT-Online\\VD_Y_0000000028\\VD_LABELED_L0.CSV\n",
      "Current video (57 of 70): ..\\Dataset\\YT-Online\\VD_Y_0000000029\\VD_LABELED_L0.CSV\n",
      "Current video (58 of 70): ..\\Dataset\\YT-Online\\VD_Y_0000000030\\VD_LABELED_L0.CSV\n",
      "Current video (59 of 70): ..\\Dataset\\YT-Online\\VD_Y_0000000031\\VD_LABELED_L0.CSV\n",
      "Current video (60 of 70): ..\\Dataset\\YT-Online\\VD_Y_0000000032\\VD_LABELED_L0.CSV\n",
      "Current video (61 of 70): ..\\Dataset\\YT-Online\\VD_Y_0000000033\\VD_LABELED_L0.CSV\n",
      "Current video (62 of 70): ..\\Dataset\\YT-Online\\VD_Y_0000000034\\VD_LABELED_L0.CSV\n",
      "Current video (63 of 70): ..\\Dataset\\YT-Online\\VD_Y_0000000035\\VD_LABELED_L0.CSV\n",
      "Current video (64 of 70): ..\\Dataset\\YT-Online\\VD_Y_0000000036\\VD_LABELED_L0.CSV\n",
      "Current video (65 of 70): ..\\Dataset\\YT-Online\\VD_Y_0000000037\\VD_LABELED_L0.CSV\n",
      "Current video (66 of 70): ..\\Dataset\\YT-Online\\VD_Y_0000000038\\VD_LABELED_L0.CSV\n",
      "Current video (67 of 70): ..\\Dataset\\YT-Online\\VD_Y_0000000039\\VD_LABELED_L0.CSV\n",
      "Current video (68 of 70): ..\\Dataset\\YT-Online\\VD_Y_0000000040\\VD_LABELED_L0.CSV\n",
      "Current video (69 of 70): ..\\Dataset\\YT-Online\\VD_Y_0000000041\\VD_LABELED_L0.CSV\n",
      "Current video (70 of 70): ..\\Dataset\\YT-Online\\VD_Y_0000000042\\VD_LABELED_L0.CSV\n",
      "\n",
      "Saving file result_sequences\\DATASET_SEQUENCES_8.CSV...\n"
     ]
    }
   ],
   "source": [
    "num_file_sequences = len(gf.find_files_in_all_subdirectories([os.path.join('.', 'result_sequences')], '*.CSV'))\n",
    "OUTPUT_NAME = os.path.join('result_sequences','DATASET_SEQUENCES_' + str(num_file_sequences+1) + '.CSV')\n",
    "DATASET_SEQUENCES = pd.DataFrame()\n",
    "\n",
    "idx_sample = 0\n",
    "for i, current_path_location in enumerate(MAIN_LIST_LABELER[:]):\n",
    "    VD_LABELED_DT = pd.read_csv(current_path_location)\n",
    "    VD_LABELED_DT.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "\n",
    "    print(f\"Current video ({i+1} of {len(MAIN_LIST_LABELER)}):\", current_path_location)\n",
    "\n",
    "    for group in VD_LABELED_DT.groupby('label_measures'):\n",
    "        \n",
    "        if len(group[0]) > 5:\n",
    "            label_measure_string = group[0]\n",
    "            parsed_object = parse_string_to_object(label_measure_string)\n",
    "            emotion_name, emotion_data = get_emotion_with_min_value(parsed_object)\n",
    "\n",
    "            emotion_euclidean_dist = emotion_data[1]\n",
    "            emotion_reference_seed = emotion_data[2]\n",
    "\n",
    "            current_insertion = group[1].copy()\n",
    "            current_insertion['label'] = str(emotion_name)\n",
    "            current_insertion['euclidean_dist'] = emotion_euclidean_dist\n",
    "            current_insertion['reference_seed'] = emotion_reference_seed\n",
    "            current_insertion['sample_id'] = idx_sample\n",
    "\n",
    "            cols = list(current_insertion.columns)\n",
    "            cols.insert(1, cols.pop(cols.index('sample_id')))\n",
    "            current_insertion = current_insertion[cols]\n",
    "\n",
    "            idx_sample += 1\n",
    "\n",
    "            DATASET_SEQUENCES = pd.concat([DATASET_SEQUENCES, current_insertion], axis=0)\n",
    "\n",
    "print(f'\\nSaving file {OUTPUT_NAME}...')\n",
    "DATASET_SEQUENCES.to_csv(OUTPUT_NAME)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "t3-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
