{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-27 14:18:43.452134: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-27 14:18:43.455534: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-27 14:18:43.498548: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-27 14:18:44.280347: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os, sys, pandas as pd, numpy as np\n",
    "\n",
    "# Import library with current code functions\n",
    "sys.path.append(os.path.join(\"..\", \"lib\"))\n",
    "import neural_network_functions as neural_net_fun, general_functions as gf, files_paths as fp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get all the VD_LABELED files paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_LIST_VD_INFO = gf.find_files_in_all_subdirectories([fp.DATASET_YT, fp.DATASET_LOCAL], fp.VD_INFO)\n",
    "FILE_LIST_VD_LABELED = gf.find_files_in_all_subdirectories([fp.DATASET_YT, fp.DATASET_LOCAL], fp.VD_LABELED_L0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenate all CSV with labeled series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty DataFrame\n",
    "data = pd.DataFrame()\n",
    "\n",
    "for current_csv_path in FILE_LIST_VD_LABELED:\n",
    "    current_data = pd.read_csv(current_csv_path)\n",
    "    data = pd.concat([data, current_data], ignore_index=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess your data, define your model and them train it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-27 14:18:46.373479: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:282] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    }
   ],
   "source": [
    "# Preprocess your data\n",
    "cleaned_data = neural_net_fun.preprocess_data(data)\n",
    "\n",
    "# Separate the X, y at train and test\n",
    "X_train, X_test, y_train, y_test, timesteps, features, features_names, classes = neural_net_fun.my_train_test_split(cleaned_data)\n",
    "\n",
    "# Define your model\n",
    "model = neural_net_fun.define_model(timesteps, len(features_names), len(classes))\n",
    "\n",
    "# Using Gaussian Noise to augment the data\n",
    "model_with_noise = neural_net_fun.define_model_with_noise(timesteps, len(features_names), len(classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set of train features X_train:\n",
      " (60693, 1, 22)\n",
      "Set of train targets y_train:\n",
      " (60693, 3)\n",
      "Set of test features X_test:\n",
      " (15174, 1, 22)\n",
      "Set of test targets y_test:\n",
      " (15174, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"Set of train features X_train:\\n\", X_train.shape)\n",
    "print(\"Set of train targets y_train:\\n\", y_train.shape)\n",
    "print(\"Set of test features X_test:\\n\", X_test.shape)\n",
    "print(\"Set of test targets y_test:\\n\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9336 - loss: 0.3077 - val_accuracy: 0.9521 - val_loss: 0.1991\n",
      "Epoch 2/10\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9533 - loss: 0.1885 - val_accuracy: 0.9518 - val_loss: 0.1848\n",
      "Epoch 3/10\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9511 - loss: 0.1899 - val_accuracy: 0.9522 - val_loss: 0.1949\n",
      "Epoch 4/10\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9532 - loss: 0.1861 - val_accuracy: 0.9520 - val_loss: 0.1898\n",
      "Epoch 5/10\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9523 - loss: 0.1845 - val_accuracy: 0.9520 - val_loss: 0.1830\n",
      "Epoch 6/10\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9534 - loss: 0.1795 - val_accuracy: 0.9522 - val_loss: 0.1860\n",
      "Epoch 7/10\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9530 - loss: 0.1804 - val_accuracy: 0.9522 - val_loss: 0.1827\n",
      "Epoch 8/10\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9536 - loss: 0.1778 - val_accuracy: 0.9522 - val_loss: 0.1917\n",
      "Epoch 9/10\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9541 - loss: 0.1756 - val_accuracy: 0.9520 - val_loss: 0.1809\n",
      "Epoch 10/10\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9526 - loss: 0.1781 - val_accuracy: 0.9517 - val_loss: 0.1819\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=10, batch_size=64, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model with Gaussian noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9516 - loss: 0.2135 - val_accuracy: 0.9522 - val_loss: 0.1865\n",
      "Epoch 2/10\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9526 - loss: 0.1885 - val_accuracy: 0.9522 - val_loss: 0.1850\n",
      "Epoch 3/10\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9513 - loss: 0.1874 - val_accuracy: 0.9522 - val_loss: 0.1817\n",
      "Epoch 4/10\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9525 - loss: 0.1868 - val_accuracy: 0.9522 - val_loss: 0.1817\n",
      "Epoch 5/10\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9509 - loss: 0.1865 - val_accuracy: 0.9522 - val_loss: 0.1875\n",
      "Epoch 6/10\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9528 - loss: 0.1840 - val_accuracy: 0.9522 - val_loss: 0.1798\n",
      "Epoch 7/10\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9506 - loss: 0.1879 - val_accuracy: 0.9522 - val_loss: 0.1804\n",
      "Epoch 8/10\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9526 - loss: 0.1826 - val_accuracy: 0.9522 - val_loss: 0.1803\n",
      "Epoch 9/10\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9532 - loss: 0.1784 - val_accuracy: 0.9522 - val_loss: 0.1823\n",
      "Epoch 10/10\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9535 - loss: 0.1781 - val_accuracy: 0.9522 - val_loss: 0.1793\n"
     ]
    }
   ],
   "source": [
    "history_with_noise = model_with_noise.fit(X_train, y_train, epochs=10, batch_size=64, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 877us/step - accuracy: 0.9536 - loss: 0.1793\n",
      "Test Accuracy: 0.9517\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Test Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model with Gaussian Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 702us/step - accuracy: 0.9542 - loss: 0.1756\n",
      "Test Accuracy: 0.9522\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model_with_noise.evaluate(X_test, y_test)\n",
    "print(f'Test Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('lstm_time_series_model.keras')\n",
    "\n",
    "# Gaussian noised model\n",
    "model_with_noise.save('lstm_time_series_model_noise.keras')\n",
    "\n",
    "# Save the classes object\n",
    "np.save('classes.npy', classes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
