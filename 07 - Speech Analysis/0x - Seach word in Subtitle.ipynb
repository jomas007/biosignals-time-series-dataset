{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## One Time Labeler\n",
    "# 1 - Generates an index with information about reference series.\n",
    "## 1.1 - Selects the video for analysis.\n",
    "# 2 - Analyzes the graphs of the selected video series\n",
    "# 3 - Loads frames from the selected video for further image analysis \n",
    "## 3.1 - select the range of frames to be loaded or load all video frames (maximum of 1000 frames).\n",
    "## 3.2 - Displays frames for image analysis - enter values for the range of frames to be shown.\n",
    "# 4 - Reads or creates the VD_LABELED file if it does not exist.\n",
    "# 5 - Adds information to label the frames.\n",
    "# 6 - Functions to verify the added labels.\n",
    "## 6.1 - Gets all saved label classes.\n",
    "## 6.2 - Gets the frames marked with a selected class.\n",
    "## 6.3 - Gets reference measurements for each class.\n",
    "## 6.4 - Plots a graph marking the start and end of the labels for a class.\n",
    "# 7 - Saves the VD_LABELED file to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.29.1.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import sys\n",
    "import pandas as pd\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import ast\n",
    "import cv2\n",
    "\n",
    "from dash import Dash, dcc, html, Input, Output, ctx\n",
    "import plotly.express as px\n",
    "import plotly.offline as py\n",
    "import plotly.graph_objs as go\n",
    "import webbrowser\n",
    "from threading import Timer\n",
    "import json\n",
    "\n",
    "py.init_notebook_mode(connected=True)\n",
    "plt.rcParams['font.size'] = 10\n",
    "plt.rcParams[\"font.family\"] = \"Times New Roman\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scan Folder and Find\n",
    "def list_scan_from_path (baseDir, file_name):\n",
    "    ## 1.VD_FEATURES_Lx.CSV\n",
    "    MAIN_VD_FEATURES_LX = []\n",
    "    # Scan the Folder and Save the list[]\n",
    "    FOLDER_CSV_SCAN = glob.iglob( baseDir + os.sep + '**' + os.sep + '*.CSV', recursive=True )\n",
    "    # Order By Name\n",
    "    FOLDER_CSV_SCAN = sorted(FOLDER_CSV_SCAN)\n",
    "    # Interate frame by frame\n",
    "    for filename in FOLDER_CSV_SCAN:\n",
    "        #print (filename.find('VD_INFO') != -1)\n",
    "        if (filename.find(file_name) != -1) == True:\n",
    "            #print (filename)\n",
    "            MAIN_VD_FEATURES_LX.append(filename)\n",
    "        #\n",
    "    # Return the list\n",
    "    return MAIN_VD_FEATURES_LX\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect the base\n",
    "def collect_basex (original_path):\n",
    "    xpath = original_path.split(os.sep)\n",
    "    new_path = ''\n",
    "    ii=0\n",
    "    for parts in xpath:\n",
    "        if ii <= len(xpath)-2:\n",
    "            new_path += parts + str(os.sep)\n",
    "        ii += 1\n",
    "    # Return\n",
    "    return new_path\n",
    "#<chg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot serie\n",
    "def plot_time_series(time, values, label):\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.plot(time, values)\n",
    "    plt.xlabel(\"Time\", fontsize=20)\n",
    "    plt.ylabel(\"Value\", fontsize=20)\n",
    "    plt.title(label, fontsize=20)\n",
    "    plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def READ_CSV_FILE(base_path, file_name=None):\n",
    "    if file_name:\n",
    "        file_path = os.path.join(base_path, file_name)\n",
    "    else: file_path = base_path\n",
    "    # Read the Dataframe from CSV\n",
    "    current_dt = pd.read_csv(file_path)\n",
    "    try:\n",
    "        # Remove the Unamed columns\n",
    "        current_dt.drop(columns=[\"Unnamed: 0\"], inplace=True)\n",
    "    except: pass\n",
    "    return current_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CREATE_LABELED_INDEX(FILE_LOCATION_TREE_DLOCAL, VD_INFO_FILE_NAME = 'VD_INFO.CSV', VD_LABEL_FILE_NAME = 'VD_LABELED_L0.CSV'):\n",
    "    INDEX_REF_DT = pd.DataFrame()\n",
    "    \n",
    "    for measure_path in FILE_LOCATION_TREE_DLOCAL:\n",
    "        current_path = collect_basex(measure_path)\n",
    "        path_vd_info = os.path.join(current_path, VD_INFO_FILE_NAME)\n",
    "        # Read the Dataframe from CSV\n",
    "        current_vd_info = pd.read_csv(path_vd_info)\n",
    "        # Remove the Unamed columns\n",
    "        current_vd_info.drop(columns=[\"Unnamed: 0\"], inplace=True)\n",
    "        SELECT_DT = current_vd_info[['video_id', 'link_video', 'duration_vid', 'total_frames']].copy()\n",
    "        path_vd_label = os.path.join(current_path, VD_LABEL_FILE_NAME)\n",
    "        if os.path.exists(path_vd_label):\n",
    "            SELECT_DT.loc[:,'label_file_exist']=1\n",
    "        else:\n",
    "            SELECT_DT.loc[:,'label_file_exist']=0\n",
    "        SELECT_DT['path'] = current_path\n",
    "        INDEX_REF_DT = pd.concat([INDEX_REF_DT, SELECT_DT], ignore_index=True)\n",
    "    INDEX_REF_DT = INDEX_REF_DT.set_index(pd.Index(INDEX_REF_DT['video_id']))\n",
    "    INDEX_REF_DT.drop(columns=[\"video_id\"], inplace=True)\n",
    "        \n",
    "    return INDEX_REF_DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to organize the marked frames in a list into sublists containing continuous frames.\n",
    "def separate_intervals(lst):\n",
    "    # Sort the list to ensure numbers are in ascending order\n",
    "    sorted_list = sorted(lst)\n",
    "    \n",
    "    # Initialize the intervals list\n",
    "    intervals = []\n",
    "    \n",
    "    # Initialize the start and end of interval\n",
    "    start_interval = sorted_list[0]\n",
    "    end_interval = sorted_list[0]\n",
    "    \n",
    "    # Iterate over the sorted list\n",
    "    for num in sorted_list[1:]:\n",
    "        # If the current number is equal to the previous number + 1, continue the interval\n",
    "        if num == end_interval + 1:\n",
    "            end_interval = num\n",
    "        # If not, the interval has ended, so add it to the intervals list and start a new interval\n",
    "        else:\n",
    "            intervals.append((start_interval, end_interval))\n",
    "            start_interval = num\n",
    "            end_interval = num\n",
    "    \n",
    "    # Add the last interval to the intervals list\n",
    "    intervals.append((start_interval, end_interval))\n",
    "    \n",
    "    return intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot a graph with markers for the classes\n",
    "def PLOT_CLASS_GRAPH(VD_LABELED_DT, class_in, start_frame=None, end_frame=None):\n",
    "    fonte = {'family': \"Times New Roman\", 'color': 'black', 'weight': 'bold', 'size': 10}\n",
    "    \n",
    "    get_measur = GET_MEASURES_FROM_CLASS (VD_LABELED_DT, class_in)\n",
    "    frames_f_class = GET_FRAMES_FROM_CLASS(VD_LABELED_DT, class_in)\n",
    "    frames_f_class= separate_intervals(frames_f_class)\n",
    "    PLOT_DT = VD_MEASURE_DT_V2[get_measur].copy()\n",
    "\n",
    "    if start_frame is not None and end_frame is not None:\n",
    "        PLOT_DT = PLOT_DT[start_frame:end_frame+1]\n",
    "        \n",
    "    # Plot graph\n",
    "    fig, ax = plt.subplots(figsize=(9, 3))\n",
    "    #plt.figure(figsize=(fig_width, fig_height))\n",
    "    ax.plot(PLOT_DT.index, PLOT_DT, label=get_measur)\n",
    "    \n",
    "    for interval in frames_f_class:\n",
    "        ax.fill_between(interval, 0, 1, alpha=0.2, transform=ax.get_xaxis_transform(), label=f'{class_in}: {interval}')\n",
    "        #ax.text(interval[0], 6, f'{interval[0]}', fontsize=10)\n",
    "        #ax.text(interval[1], 6, f'{interval[1]}', fontsize=10)\n",
    "        #ax.annotate(f'{interval}', xy=(2, 1), xytext=(3, 4), arrowprops=dict(facecolor='black', shrink=0.05))\n",
    "    #plt.xticks(PLOT_DT.index)\n",
    "    ax.set_ylim(ymin=0)\n",
    "    ax.set_xlim(xmin=0)\n",
    "    plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    plt.ylabel('Amplitude (pixel)', fontdict=fonte)\n",
    "    plt.xlabel('Frame number', fontdict=fonte)\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('graph.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init process\n",
    "# Variables\n",
    "\n",
    "# LOCAL DIR\n",
    "tree_DIR_LD = 'Dataset' + os.sep + 'YT-Online'\n",
    "baseDir_LD = '..' + os.sep + tree_DIR_LD + os.sep\n",
    "\n",
    "# Tree List\n",
    "FILE_LOCATION_TREE_DLOCAL = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File_name to find\n",
    "file_name_fd = 'VD_SUBTITLES.CSV'\n",
    "# Call the basic function to find all VD_MEASURE_L0 files\n",
    "FILE_LOCATION_TREE_DLOCAL = list_scan_from_path (baseDir_LD, file_name_fd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['..\\\\Dataset\\\\YT-Online\\\\VD_Y_0000000001\\\\VD_SUBTITLES.CSV',\n",
       " '..\\\\Dataset\\\\YT-Online\\\\VD_Y_0000000002\\\\VD_SUBTITLES.CSV',\n",
       " '..\\\\Dataset\\\\YT-Online\\\\VD_Y_0000000003\\\\VD_SUBTITLES.CSV',\n",
       " '..\\\\Dataset\\\\YT-Online\\\\VD_Y_0000000004\\\\VD_SUBTITLES.CSV',\n",
       " '..\\\\Dataset\\\\YT-Online\\\\VD_Y_0000000005\\\\VD_SUBTITLES.CSV',\n",
       " '..\\\\Dataset\\\\YT-Online\\\\VD_Y_0000000006\\\\VD_SUBTITLES.CSV',\n",
       " '..\\\\Dataset\\\\YT-Online\\\\VD_Y_0000000007\\\\VD_SUBTITLES.CSV',\n",
       " '..\\\\Dataset\\\\YT-Online\\\\VD_Y_0000000008\\\\VD_SUBTITLES.CSV',\n",
       " '..\\\\Dataset\\\\YT-Online\\\\VD_Y_0000000009\\\\VD_SUBTITLES.CSV',\n",
       " '..\\\\Dataset\\\\YT-Online\\\\VD_Y_0000000011\\\\VD_SUBTITLES.CSV',\n",
       " '..\\\\Dataset\\\\YT-Online\\\\VD_Y_0000000012\\\\VD_SUBTITLES.CSV',\n",
       " '..\\\\Dataset\\\\YT-Online\\\\VD_Y_0000000013\\\\VD_SUBTITLES.CSV',\n",
       " '..\\\\Dataset\\\\YT-Online\\\\VD_Y_0000000014\\\\VD_SUBTITLES.CSV',\n",
       " '..\\\\Dataset\\\\YT-Online\\\\VD_Y_0000000015\\\\VD_SUBTITLES.CSV',\n",
       " '..\\\\Dataset\\\\YT-Online\\\\VD_Y_0000000016\\\\VD_SUBTITLES.CSV',\n",
       " '..\\\\Dataset\\\\YT-Online\\\\VD_Y_0000000017\\\\VD_SUBTITLES.CSV',\n",
       " '..\\\\Dataset\\\\YT-Online\\\\VD_Y_0000000018\\\\VD_SUBTITLES.CSV',\n",
       " '..\\\\Dataset\\\\YT-Online\\\\VD_Y_0000000020\\\\VD_SUBTITLES.CSV',\n",
       " '..\\\\Dataset\\\\YT-Online\\\\VD_Y_0000000022\\\\VD_SUBTITLES.CSV',\n",
       " '..\\\\Dataset\\\\YT-Online\\\\VD_Y_0000000024\\\\VD_SUBTITLES.CSV',\n",
       " '..\\\\Dataset\\\\YT-Online\\\\VD_Y_0000000027\\\\VD_SUBTITLES.CSV',\n",
       " '..\\\\Dataset\\\\YT-Online\\\\VD_Y_0000000028\\\\VD_SUBTITLES.CSV',\n",
       " '..\\\\Dataset\\\\YT-Online\\\\VD_Y_0000000030\\\\VD_SUBTITLES.CSV',\n",
       " '..\\\\Dataset\\\\YT-Online\\\\VD_Y_0000000031\\\\VD_SUBTITLES.CSV',\n",
       " '..\\\\Dataset\\\\YT-Online\\\\VD_Y_0000000032\\\\VD_SUBTITLES.CSV',\n",
       " '..\\\\Dataset\\\\YT-Online\\\\VD_Y_0000000033\\\\VD_SUBTITLES.CSV',\n",
       " '..\\\\Dataset\\\\YT-Online\\\\VD_Y_0000000034\\\\VD_SUBTITLES.CSV',\n",
       " '..\\\\Dataset\\\\YT-Online\\\\VD_Y_0000000035\\\\VD_SUBTITLES.CSV',\n",
       " '..\\\\Dataset\\\\YT-Online\\\\VD_Y_0000000036\\\\VD_SUBTITLES.CSV',\n",
       " '..\\\\Dataset\\\\YT-Online\\\\VD_Y_0000000037\\\\VD_SUBTITLES.CSV']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FILE_LOCATION_TREE_DLOCAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..\\Dataset\\YT-Online\\VD_Y_0000000002\\VD_SUBTITLES.CSV\n",
      "                                       text    start  duration\n",
      "17  FREE VACCINES HAVE BEEN AVAILABLE IN 80   41.120     5.279\n",
      "19          WE STILL HAVE NEARLY 80 MILLION   46.399     3.680\n",
      "20     AMERICANS WHO HAVE FAILED TO GET THE   48.160     3.440\n",
      "46     LARGE MAJORITY OF AMERICANS WHO HAVE  106.560     3.839\n",
      "..\\Dataset\\YT-Online\\VD_Y_0000000004\\VD_SUBTITLES.CSV\n",
      "                                       text  start  duration\n",
      "4  HAVE DEVELOPED A FORMULA TO HELP YOU ACE  11.37      6.09\n",
      "..\\Dataset\\YT-Online\\VD_Y_0000000005\\VD_SUBTITLES.CSV\n",
      "                                      text  start  duration\n",
      "21  YOU HAVE WITH CLIENT WHERE YOU HAVE TO  43.68      4.23\n",
      "..\\Dataset\\YT-Online\\VD_Y_0000000006\\VD_SUBTITLES.CSV\n",
      "                                         text    start  duration\n",
      "64      IF YOU HAVEN'T DRESSED PROFESSIONALLY  114.560     4.080\n",
      "76            INTERVIEW YOU HAVE GOOD POSTURE  135.840     5.440\n",
      "103                     HAVE THAT ARE A MATCH  187.519     4.241\n",
      "111  YOU HAVE GAINED IN WORK LIFE OR PERSONAL  203.360     3.920\n",
      "133   I HAVE THE SKILLS THE QUALITIES AND THE  242.159     3.681\n",
      "139      I HAVE AN IMPRESSIVE TRACK RECORD OF  255.120     2.720\n",
      "177   WHICH MEANS YOU CAN HAVE IT WITHIN YOUR  325.199     3.761\n",
      "191                      HAVE A BRILLIANT DAY  351.520     3.119\n",
      "..\\Dataset\\YT-Online\\VD_Y_0000000007\\VD_SUBTITLES.CSV\n",
      "                                                 text  start  duration\n",
      "8                     BECAUSE I HAVE A SECRET FORMULA  26.72      2.24\n",
      "19  SOMETIMES COMPANIES DON'T KNOW IF THEY'LL HAVE...  84.78      6.96\n",
      "..\\Dataset\\YT-Online\\VD_Y_0000000008\\VD_SUBTITLES.CSV\n",
      "                                                 text   start  duration\n",
      "17  AND YOU HAVE TO TALK TO A GROUP OF\\nSTRANGERS ...   88.79      3.99\n",
      "28  MOUTHS YOU'RE GONNA BE ABLE TO HAVE MORE\\nVALU...  134.84      4.38\n",
      "48  HAVE TO GIVE THAT ENERGY SAYING THINGS\\nLIKE T...  223.67      5.75\n",
      "54  PERSON IS TALKING ABOUT THE STORY\\nOBVIOUSLY H...  254.60      4.35\n",
      "74  THEY KNOW THAT THEY'RE GONNA HAVE TO\\nMEET THE...  342.32      3.00\n",
      "79  DOESN'T HURT TO PRACTICE AHEAD OF TIME\\nYOU WA...  363.20      4.74\n",
      "84  NEXT TIME THAT YOU HAVE TO GO INTO A\\nGROUP ME...  385.37      4.29\n",
      "86  AND CONFIDENT WAY SO THERE YOU HAVE IT\\nMY FOU...  394.25      4.47\n",
      "89  YOU'VE BEEN GOING ON INTERVIEWS BUT YOU\\nJUST ...  406.61      3.66\n",
      "..\\Dataset\\YT-Online\\VD_Y_0000000009\\VD_SUBTITLES.CSV\n",
      "                                       text  start  duration\n",
      "6   SOME OF THE STRATEGIES THAT HAVE HELPED  15.96      4.67\n",
      "10  FACEBOOK AND MORE IMPORTANTLY THAT HAVE  26.73      5.01\n",
      "..\\Dataset\\YT-Online\\VD_Y_0000000011\\VD_SUBTITLES.CSV\n",
      "                                        text    start  duration\n",
      "23          HAVE TO GIVE A SIXTY SECOND SELF   44.579     4.410\n",
      "71        HAVE TO DO TO SORT OF WRAP UP THAT  144.230     3.960\n",
      "79      A NEAT LITTLE TIDY WAY TO HAVE THREE  160.790     3.809\n",
      "97  YOU HAVE ANY QUESTIONS OR COMMENTS ABOUT  197.750     2.819\n",
      "..\\Dataset\\YT-Online\\VD_Y_0000000013\\VD_SUBTITLES.CSV\n",
      "                    text   start  duration\n",
      "32  AND HAVE A GREAT DAY  79.229     3.261\n",
      "..\\Dataset\\YT-Online\\VD_Y_0000000014\\VD_SUBTITLES.CSV\n",
      "                                       text  start  duration\n",
      "3  HAVE A DEGREE IN LINGUISTICS AND ENGLISH   6.54     5.070\n",
      "6     FRANCE I HAVE A WIDE RANGE OF HOBBIES  14.61     7.589\n",
      "..\\Dataset\\YT-Online\\VD_Y_0000000015\\VD_SUBTITLES.CSV\n",
      "                                        text   start  duration\n",
      "10    HAVE TO PREVENT A LOT OF TARDINESS AND  27.599     3.600\n",
      "12     SINCE WE ONLY HAVE SIX WEEKS TO SPARE  31.199     6.161\n",
      "13          I EXPECT TO HAVE A LOT OF ONLINE  35.200     4.240\n",
      "31  WE CANNOT HAVE FACE-TO-FACE CLASS DUE TO  73.040     4.240\n",
      "40  AND HAVE AN ENJOYABLE CLASS WITH HER AND  94.400     3.679\n",
      "..\\Dataset\\YT-Online\\VD_Y_0000000016\\VD_SUBTITLES.CSV\n",
      "                               text   start  duration\n",
      "25    WE DON'T HAVE THE SAME STABLE  72.000     6.960\n",
      "28  THE INTERNET THAT THEY HAVE AND  82.479     5.361\n",
      "..\\Dataset\\YT-Online\\VD_Y_0000000020\\VD_SUBTITLES.CSV\n",
      "                          text   start  duration\n",
      "19                      I HAVE   44.00      3.44\n",
      "36          I HAVE JOINED MANY   81.52      3.68\n",
      "67  WHICH HAVE DIFFERENT NEEDS  160.64      4.48\n",
      "..\\Dataset\\YT-Online\\VD_Y_0000000024\\VD_SUBTITLES.CSV\n",
      "                                       text   start  duration\n",
      "4  IN LYCEUM NORTHWESTERN UNIVERSITY I HAVE  10.349     5.731\n",
      "7            ALSO HAVE MY TESOL CERTIFICATE  18.480     5.969\n",
      "..\\Dataset\\YT-Online\\VD_Y_0000000027\\VD_SUBTITLES.CSV\n",
      "                                       text  start  duration\n",
      "6  UNDERSTAND BUT YOU HAVE NOTHING TO WORRY  19.14     5.700\n",
      "8    GUIDE YOU I HAVE BEEN TEACHING ENGLISH  24.84     5.009\n",
      "9        FOR FEARS NOW AND HAVE COME ACROSS  27.30     5.279\n",
      "..\\Dataset\\YT-Online\\VD_Y_0000000028\\VD_SUBTITLES.CSV\n",
      "                                      text   start  duration\n",
      "8   LANGUAGE TRAINING I HAVE BEEN TEACHING  24.150     5.459\n",
      "16                 HAVE FUN WHILE LEARNING  46.649     5.011\n",
      "18   WILL NOT JUST HAVE ME AS YOUR TEACHER  51.660     4.919\n",
      "..\\Dataset\\YT-Online\\VD_Y_0000000030\\VD_SUBTITLES.CSV\n",
      "                                        text    start  duration\n",
      "19  ENGLISH TEACHER I HAVE BEEN TEACHING FOR   49.649      3.84\n",
      "37   WELL IN FACT I DO HAVE A LOT OF HOBBIES   97.700      6.66\n",
      "43   ANIMALS A LOT ACTUALLY I HAVE A DOGS AT  118.740      6.18\n",
      "..\\Dataset\\YT-Online\\VD_Y_0000000031\\VD_SUBTITLES.CSV\n",
      "                                                text   start  duration\n",
      "8  ABOUT THE PRESENTATIONS THAT YOU HAVE\\nALREADY...  38.850     3.389\n",
      "9  MAYBE THEPRESENTATIONS THAT YOU HAVE DONE\\nYOU...  42.239     2.963\n",
      "..\\Dataset\\YT-Online\\VD_Y_0000000032\\VD_SUBTITLES.CSV\n",
      "                                      text  start  duration\n",
      "2  ONTARIO CANADA NOT ONLY THAT BUT I HAVE   9.96     6.659\n",
      "6      ALSO I HAVE BEEN TEACHING DIFFERENT  25.01     6.030\n",
      "..\\Dataset\\YT-Online\\VD_Y_0000000033\\VD_SUBTITLES.CSV\n",
      "                                        text  start  duration\n",
      "19  HAVE A CLASS WITH AND THAT MAKES MOST OF  68.82      6.24\n",
      "..\\Dataset\\YT-Online\\VD_Y_0000000034\\VD_SUBTITLES.CSV\n",
      "                                        text   start  duration\n",
      "11  BECAUSE I WANT TO SHOW THE TALENT I HAVE  25.599     4.321\n",
      "12  TO A LOT OF PEOPLE AND I'M ALWAYS HAVE A  27.760     3.919\n",
      "..\\Dataset\\YT-Online\\VD_Y_0000000035\\VD_SUBTITLES.CSV\n",
      "                                        text   start  duration\n",
      "4    I HAVE TAUGHT ENGLISH IN THAILAND SOUTH  12.870     5.610\n",
      "7   HAVE BEEN DOING THAT FOR ABOUT TWO YEARS  21.060     6.209\n",
      "8           NOW I ALSO HAVE A 150 HOUR TESOL  22.769     5.580\n",
      "23    I HAVE BEEN TEACHING STUDENTS IN CHINA  60.750     5.610\n",
      "..\\Dataset\\YT-Online\\VD_Y_0000000036\\VD_SUBTITLES.CSV\n",
      "                                        text   start  duration\n",
      "4           STAYING IN BHOPAL I HAVE DONE MY  10.019     4.080\n",
      "6   SCHOOL AMLA I HAVE SECURED 81 PERCENT IN  14.099     5.701\n",
      "18    I HAVE DONE INDUSTRIALLY VISIT SATPURA  43.920     6.360\n",
      "19       POWER PLANT SANI AND I HAVE DONE UH  46.739     5.761\n",
      "25           ELECTRICITY TRANSMISSION I HAVE  63.180     5.640\n",
      "32   DRAMAS AND BRANCH MASTER I HAVE SECURED  80.840     5.560\n",
      "..\\Dataset\\YT-Online\\VD_Y_0000000037\\VD_SUBTITLES.CSV\n",
      "                                                 text   start  duration\n",
      "9        IT DOESN'T MATTER IF\\nYOU HAVE THREE MINUTES   28.76      2.24\n",
      "22               I AM SUPER EXCITED TO HAVE YOU HERE,   70.24      2.52\n",
      "23  EXCITED ABOUT THE CONVERSATION\\nWE'LL GET TO H...   72.76      3.46\n",
      "28                           WE HAVE NO SLIDES TODAY.   88.19      2.47\n",
      "34       I SAY THAT BECAUSE YOU\\nCOULD HAVE BEEN HOME  106.14      2.69\n",
      "50                    THAT WAY, ALL YOU'LL HAVE TO DO  151.00      1.59\n",
      "56                                HAVE AN AMAZING DAY  164.71      1.72\n"
     ]
    }
   ],
   "source": [
    "word = 'HAVE'\n",
    "result_final = pd.DataFrame()\n",
    "aux = pd.DataFrame(data=[0])\n",
    "# Função para verificar se a palavra específica está presente em cada texto\n",
    "def search_word(texto):\n",
    "    return word in texto\n",
    "\n",
    "for current_path in FILE_LOCATION_TREE_DLOCAL:\n",
    "    SUB_DT = READ_CSV_FILE(current_path)\n",
    "    SUB_DT['finded_word'] = SUB_DT['text'].apply(search_word)\n",
    "    result = SUB_DT.loc[SUB_DT['finded_word']]\n",
    "    if len(result) > 0:\n",
    "        print(current_path)\n",
    "        print(result.iloc[:,0:3])\n",
    "        result_select = result.iloc[:,0:3]\n",
    "        result_select['path'] = current_path\n",
    "        result_final = pd.concat([result_final,result_select])\n",
    "        \n",
    "        result_final = pd.concat([result_final,aux])\n",
    "\n",
    "result_final.to_csv(f'{word}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "## 1.1 - Selects the video for analysis and CSV data file\n",
    "#\n",
    "# Type the video id to label\n",
    "VIDEO_ID = 1\n",
    "#\n",
    "# Read CSV data file\n",
    "VD_MEASURE_FILE_NAME = 'VD_SUBTITLES.CSV'\n",
    "VD_MEASURE_DT = READ_CSV_FILE(FILE_LOCATION_TREE_DLOCAL[VIDEO_ID-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#VD_MEASURE_DT_V2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
