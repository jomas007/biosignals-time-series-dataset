{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "krIbpVV3dX4c"
   },
   "source": [
    "## Importing dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4EqW0UI6Yre3"
   },
   "outputs": [],
   "source": [
    "import os, glob, sys, pandas as pd\n",
    "\n",
    "# Library to collect the video information's\n",
    "from moviepy.editor import *\n",
    "\n",
    "# Import library with current code functions\n",
    "sys.path.append(os.path.join(\"..\", \"lib\"))\n",
    "import indexer_functions as indx_fun, general_functions as gf, files_paths as fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6q_H3n_MYrfA"
   },
   "outputs": [],
   "source": [
    "VIDEO_LIST_LOCATION = os.path.join(fp.VIDEO_SOURCE_YT, 'NEW_VIDEO_LIST.LST')\n",
    "\n",
    "YT_LINKS_RAW = []\n",
    "# Insert the video's raw links into the LINKS_YT_RAW\n",
    "with open(VIDEO_LIST_LOCATION) as f:\n",
    "    for line in f:\n",
    "        out_line = line.rstrip(\"\\n\")\n",
    "        YT_LINKS_RAW.append(out_line)\n",
    "\n",
    "YT_LINKS_ID = []\n",
    "# Insert the end of the link into the YT_LINKS_ID\n",
    "for url in YT_LINKS_RAW:\n",
    "    if url.find('youtube.com') != -1:\n",
    "        YT_LINKS_ID.append(url.split(\"v=\")[1])\n",
    "\n",
    "    elif url.find('youtu.be') != -1:\n",
    "        YT_LINKS_ID.append(url.split(\"youtu.be/\")[1])\n",
    "        \n",
    "FOLDER_PATH = os.path.join(fp.DATASET_YT, '**', fp.VD_INFO)\n",
    "FOLDER_CSV_SCAN = sorted(glob.iglob(FOLDER_PATH, recursive=True ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check which videos has the VD_INFO file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WqQ1l77fidxB"
   },
   "outputs": [],
   "source": [
    "for file in FOLDER_CSV_SCAN:\n",
    "    video_info = pd.read_csv(file)\n",
    "    video_id = video_info['link_video'][0]\n",
    "    if video_id in YT_LINKS_ID:\n",
    "        YT_LINKS_ID.remove(video_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rSz58CkedpJw"
   },
   "source": [
    "## Inserting the video information into the CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "wFsjcLI6YrfJ",
    "outputId": "0019d140-d421-46b2-fef6-b325e6a398b8"
   },
   "outputs": [],
   "source": [
    "number_of_videos = len(YT_LINKS_ID)\n",
    "VIDEO_ID = gf.collect_next_video_id(FOLDER_CSV_SCAN)\n",
    "FOLDER_PREFIX = \"VD_Y_\"\n",
    "ORIGIN_VID = 'Y'\n",
    "\n",
    "for i, video_name in enumerate(YT_LINKS_ID):\n",
    "    print (str(i+1) + \" of \"+ str(number_of_videos) + \" : \" + \"Starting to process the \" + video_name)\n",
    "\n",
    "    # Collect the video link information \n",
    "    INFO_COLLECTED_SUCCESSFULLY, SHAPE_ORIGINAL, DURATION_ORIGINAL, FPS_ORIGINAL = gf.collect_video_info(gf.get_best_url(video_name))\n",
    "    \n",
    "    if INFO_COLLECTED_SUCCESSFULLY:\n",
    "        \n",
    "        # Create the VD_INFO.CSV file\n",
    "        indx_fun.create_vd_info(VIDEO_ID, DURATION_ORIGINAL, FPS_ORIGINAL, SHAPE_ORIGINAL, FOLDER_PREFIX, fp.DATASET_YT, fp.VD_INFO, video_name, ORIGIN_VID)\n",
    "        \n",
    "        # Increment the video ID\n",
    "        VIDEO_ID += 1\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
